{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all JSON files in 'data_aggregation' & add name list json_files\n",
    "FILE_PATH = './data_aggregation'\n",
    "files = os.listdir(FILE_PATH)\n",
    "json_files = [x for x in files if x[-5:]=='.json'] # regex: _\\d{4}.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through all JSON files, add data to master_df, drop cols, & remove duplicates\n",
    "\n",
    "master_df = pd.DataFrame()\n",
    "\n",
    "for i in json_files:\n",
    "    with open(f\"{FILE_PATH}/{i}\",'r') as f:\n",
    "        data = json.load(f)\n",
    "        temp_df = json_normalize(data['result'])        \n",
    "        master_df = master_df.append(temp_df, sort=True, ignore_index=True)\n",
    "        \n",
    "master_df_sub = master_df[['amount', 'client.gvkey', 'client.legal_name', 'has_amendments', 'id',\n",
    "       'is_latest_amendment', 'registrant', 'specific_issues', 'year']]\n",
    "\n",
    "master_df_sub.sort_values(by=['id','has_amendments','is_latest_amendment'],inplace=True, na_position='first')\n",
    "\n",
    "master_df_sub.drop_duplicates(subset=['amount','client.gvkey','client.legal_name',\n",
    "                                              'id','registrant','year'], keep='last', inplace=True)\n",
    "\n",
    "master_df_sub.drop(columns=['has_amendments','is_latest_amendment'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sponsors(issues):\n",
    "    \"\"\"\n",
    "    parameters: expects the 'specific_issues' column from master_df_sub.\n",
    "    \n",
    "    description: finds sponsor names in 'specific issues', if available, and adds them to a list.\n",
    "    \n",
    "    returns: a list of sponsor names.\n",
    "    \"\"\"\n",
    "    spons = []\n",
    "    try:\n",
    "        if 'bills_by_algo' in list(issues[0].keys()):\n",
    "            for sponsors in issues[0]['bills_by_algo']:\n",
    "                lastname = sponsors['sponsor']['lastname']\n",
    "                firstname = sponsors['sponsor']['firstname']\n",
    "                name = lastname + \", \" + firstname\n",
    "                party = sponsors['sponsor']['party']\n",
    "#                 spons.append((name, party)) #may want to switch back to nested list for processing (?)\n",
    "                spons.append(name)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return spons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_sub['sponsors'] = master_df_sub.apply(lambda x: get_sponsors(x['specific_issues']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lobbyists(issues):\n",
    "    \"\"\"\n",
    "    parameters: expects the 'specific_issues' column from master_df_sub.\n",
    "    \n",
    "    description: finds lobbyist names in 'specific issues', if available, and adds them to a list.\n",
    "    \n",
    "    returns: a list of lobbyist names.\n",
    "    \"\"\"\n",
    "    lobbs = []\n",
    "    try:\n",
    "        if 'lobbyists' in issues[0].keys():\n",
    "            lobbs = issues[0]['lobbyists']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return lobbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_sub['lobbyists'] = master_df_sub.apply(lambda x: get_lobbyists(x['specific_issues']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def get_combos(sponsors, lobbyists):\n",
    "    \"\"\"\n",
    "    parameters: expects two parameters, the 'sponsors' column from master_df_sub and the 'lobbyists' column.\n",
    "    \n",
    "    description: calculates the Cartesian product between the two lists.\n",
    "    \n",
    "    returns: a list of tuples of every possible pairing between a sponsor and a lobbyist.\n",
    "    \"\"\"\n",
    "    combos = list(itertools.product(sponsors, lobbyists))\n",
    "    \n",
    "    return combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_sub['sponsor_lobbyist_combos'] = master_df_sub.apply(lambda x: get_combos(x['sponsors'],x['lobbyists']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>client.gvkey</th>\n",
       "      <th>client.legal_name</th>\n",
       "      <th>id</th>\n",
       "      <th>registrant</th>\n",
       "      <th>specific_issues</th>\n",
       "      <th>year</th>\n",
       "      <th>sponsors</th>\n",
       "      <th>lobbyists</th>\n",
       "      <th>sponsor_lobbyist_combos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>12141</td>\n",
       "      <td>Microsoft Corp</td>\n",
       "      <td>0015DE1E-7D20-4A9F-A450-D2EE176A452F</td>\n",
       "      <td>The Gibson Group, LLC</td>\n",
       "      <td>[{'text': 'H1-B Visas. Issues relating to high...</td>\n",
       "      <td>2015</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Gibson, Joseph]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>220000.0</td>\n",
       "      <td>12141</td>\n",
       "      <td>Microsoft Corp</td>\n",
       "      <td>0016DDE7-E7C1-45F1-A73C-C98887F16EF9</td>\n",
       "      <td>Barbour Griffith &amp; Rogers, LLC d/b/a BGR Holding</td>\n",
       "      <td>[{'text': '', 'gov_entities': ['U.S. House of ...</td>\n",
       "      <td>2001</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Barbour, Reeves Haley Sr, Griffith, Go Jr, Mo...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>40000.0</td>\n",
       "      <td>12141</td>\n",
       "      <td>Microsoft Corp</td>\n",
       "      <td>002625A4-7560-4F27-A87C-3E0791FFB55A</td>\n",
       "      <td>Aduston Consulting, LLC</td>\n",
       "      <td>[{'text': 'H.R. 1736 Investment in America Act...</td>\n",
       "      <td>2006</td>\n",
       "      <td>[Johnson, Nancy, Goodlatte, Bob, Thomas, Willi...</td>\n",
       "      <td>[Gallant, Karl]</td>\n",
       "      <td>[(Johnson, Nancy, Gallant, Karl), (Goodlatte, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>12141</td>\n",
       "      <td>Microsoft Corp</td>\n",
       "      <td>0048ECB8-4194-4927-83FF-8BFBDD0F09FA</td>\n",
       "      <td>K&amp;L GATES LLP</td>\n",
       "      <td>[{'text': '', 'gov_entities': ['U.S. Senate'],...</td>\n",
       "      <td>2006</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Carnevale, Amy, Gorton, Slade, Punke, Timothy...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>60000.0</td>\n",
       "      <td>12141</td>\n",
       "      <td>Microsoft Corp</td>\n",
       "      <td>006D68DB-897F-4DEB-A086-6AF6D9758C8B</td>\n",
       "      <td>FOLEY HOAG LLP</td>\n",
       "      <td>[{'text': 'Patient Protection and Affordable C...</td>\n",
       "      <td>2009</td>\n",
       "      <td>[Hastert, J., Renzi, Rick, Schwarz, John, Stab...</td>\n",
       "      <td>[Childress, Kelly, Kim, Paul, Larsson, Maia]</td>\n",
       "      <td>[(Hastert, J., Childress, Kelly), (Hastert, J....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       amount client.gvkey client.legal_name  \\\n",
       "499   30000.0        12141    Microsoft Corp   \n",
       "500  220000.0        12141    Microsoft Corp   \n",
       "502   40000.0        12141    Microsoft Corp   \n",
       "503  180000.0        12141    Microsoft Corp   \n",
       "501   60000.0        12141    Microsoft Corp   \n",
       "\n",
       "                                       id  \\\n",
       "499  0015DE1E-7D20-4A9F-A450-D2EE176A452F   \n",
       "500  0016DDE7-E7C1-45F1-A73C-C98887F16EF9   \n",
       "502  002625A4-7560-4F27-A87C-3E0791FFB55A   \n",
       "503  0048ECB8-4194-4927-83FF-8BFBDD0F09FA   \n",
       "501  006D68DB-897F-4DEB-A086-6AF6D9758C8B   \n",
       "\n",
       "                                           registrant  \\\n",
       "499                             The Gibson Group, LLC   \n",
       "500  Barbour Griffith & Rogers, LLC d/b/a BGR Holding   \n",
       "502                           Aduston Consulting, LLC   \n",
       "503                                     K&L GATES LLP   \n",
       "501                                    FOLEY HOAG LLP   \n",
       "\n",
       "                                       specific_issues  year  \\\n",
       "499  [{'text': 'H1-B Visas. Issues relating to high...  2015   \n",
       "500  [{'text': '', 'gov_entities': ['U.S. House of ...  2001   \n",
       "502  [{'text': 'H.R. 1736 Investment in America Act...  2006   \n",
       "503  [{'text': '', 'gov_entities': ['U.S. Senate'],...  2006   \n",
       "501  [{'text': 'Patient Protection and Affordable C...  2009   \n",
       "\n",
       "                                              sponsors  \\\n",
       "499                                                 []   \n",
       "500                                                 []   \n",
       "502  [Johnson, Nancy, Goodlatte, Bob, Thomas, Willi...   \n",
       "503                                                 []   \n",
       "501  [Hastert, J., Renzi, Rick, Schwarz, John, Stab...   \n",
       "\n",
       "                                             lobbyists  \\\n",
       "499                                   [Gibson, Joseph]   \n",
       "500  [Barbour, Reeves Haley Sr, Griffith, Go Jr, Mo...   \n",
       "502                                    [Gallant, Karl]   \n",
       "503  [Carnevale, Amy, Gorton, Slade, Punke, Timothy...   \n",
       "501       [Childress, Kelly, Kim, Paul, Larsson, Maia]   \n",
       "\n",
       "                               sponsor_lobbyist_combos  \n",
       "499                                                 []  \n",
       "500                                                 []  \n",
       "502  [(Johnson, Nancy, Gallant, Karl), (Goodlatte, ...  \n",
       "503                                                 []  \n",
       "501  [(Hastert, J., Childress, Kelly), (Hastert, J....  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a df with a column for (individual) sponsor and a column for (individual) lobbyist\n",
    "combos = master_df_sub[master_df_sub['sponsor_lobbyist_combos'].str.len()>0]['sponsor_lobbyist_combos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "politician_lists = master_df_sub[master_df_sub['sponsors'].str.len()>0]['sponsors']\n",
    "lobbyist_lists = master_df_sub[master_df_sub['lobbyists'].str.len()>0]['lobbyists']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_politicians = [x for i in politician_lists for x in i]\n",
    "all_lobbyists = [x for i in lobbyist_lists for x in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_df_sub[master_df_sub['client.legal_name'] == 'Time Warner Inc']"
   ]
  },
  {

   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.Graph()\n",
    "G.add_edges_from([x for i in combos for x in i]) #add all nodes & edges at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 374\n",
      "Number of edges: 1853\n",
      "Average degree:   9.9091\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all existing edges from graph\n",
    "all_graph_edges = list(G.edges())\n",
    "\n",
    "# get all non-existing edges from graph\n",
    "targets = nx.non_edges(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = nx.non_edges(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67898"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_edges = all_graph_edges + list(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1853"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_graph_features(G, list_of_edges):\n",
    "    \n",
    "#     # get common neighbors for nodes\n",
    "#     common_neighbors = [len(list(nx.common_neighbors(G, edge[0], edge[1]))) for edge in all_graph_edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortest_paths = []\n",
    "\n",
    "# for edge in all_graph_edges:\n",
    "#     path = nx.shortest_path_length(G, edge[0], edge[1])\n",
    "#     shortest_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jaccard_coefficient = [item[2] for item in list(nx.jaccard_coefficient(G, ebunch=all_graph_edges))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_Warner = master_df_sub[master_df_sub['client.legal_name'] == 'Time Warner Inc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "combos_year = Time_Warner[['year', 'sponsor_lobbyist_combos']].sort_values(by = ['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_combos = combos_year[combos_year['year'] < 2013]\n",
    "future_combos = combos_year[combos_year['year'] > 2012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TW_existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all existing lobbyist, politician pairs\n",
    "TW_existing = [x for i in existing_combos['sponsor_lobbyist_combos'] for x in i]\n",
    "# all future lobbyist, politician pairs (may include nodes not in \"existing\" graph)\n",
    "TW_future = [x for i in future_combos['sponsor_lobbyist_combos'] for x in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "TW_current_graph = nx.Graph()\n",
    "TW_current_graph.add_edges_from(TW_existing) #add all nodes & edges at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TW_existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "TW_future_graph = nx.Graph()\n",
    "TW_future_graph.add_edges_from(TW_future) #add all nodes & edges at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all possible politicians and lobbyists at time graph was made\n",
    "TW_current_graph_nodes = list(TW_current_graph.nodes())\n",
    "\n",
    "# all possible politicians and lobbyists for future time graph\n",
    "TW_future_graph_nodes = list(TW_future_graph.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_existent edges at time graph is made\n",
    "TW_targets = list(nx.non_edges(TW_current_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TW_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in TW_targets:\n",
    "    if pair[0] in all_politicians and pair[1] in all_politicians:\n",
    "        TW_targets.remove(pair)\n",
    "    if pair[0] in all_lobbyists and pair[1] in all_lobbyists:\n",
    "        TW_targets.remove(pair)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TW_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "future_classifications = []\n",
    "\n",
    "future = 0\n",
    "not_future = 0\n",
    "ignore = 0\n",
    "\n",
    "# for lobbyist, politican not connected\n",
    "for pair in TW_targets:\n",
    "    #check if lobbyist and politician, independently are in future graph list\n",
    "    if pair[0] in TW_future_graph_nodes or pair[1] in TW_future_graph_nodes:\n",
    "        #if yes, check if lobbyist and politician are a pair in future\n",
    "        if pair in TW_future:\n",
    "            future +=1\n",
    "            future_classifications.append([pair, 1])\n",
    "        else:\n",
    "            future_classifications.append([pair, 0])\n",
    "            not_future +=1\n",
    "    else:\n",
    "        ignore +=1\n",
    "        continue\n",
    "        \n",
    "print(future, not_future, ignore)\n",
    "# print(future_classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# future_classifications = []\n",
    "\n",
    "# future = 0\n",
    "# not_future = 0\n",
    "# ignore = 0\n",
    "\n",
    "# # # for lobbyist, politican connection in the future\n",
    "# for pair in TW_future:\n",
    "#     #check if lobbyist and politician are in original graph (past)\n",
    "#     if pair[0] in TW_current_graph_nodes and pair[1] in TW_current_graph_nodes:\n",
    "#         #if yes, check if lobbyist and politician were a non-exist pair in original graph (past)\n",
    "#         if pair in TW_targets:\n",
    "#             future +=1\n",
    "#             future_classifications.append([pair, 1])\n",
    "#         else:\n",
    "#             not_future +=1\n",
    "#             future_classifications.append([pair, 0])\n",
    "#     else:\n",
    "#         ignore +=1\n",
    "#         continue\n",
    "        \n",
    "# print(future, not_future, ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_function(cutoff_year):\n",
    "    \n",
    "    # create graph for entire dataset\n",
    "    yearly_data = master_df_sub[['year', 'sponsor_lobbyist_combos']].sort_values(by = ['year'])\n",
    "    total_existing = [x for i in yearly_data['sponsor_lobbyist_combos'] for x in i]\n",
    "    total_graph = nx.Graph()\n",
    "    total_graph.add_edges_from(total_existing) #add all nodes & edges at once\n",
    "    \n",
    "    #create two databases, one for current year only, and other for every year after\n",
    "    existing_combos = yearly_data[yearly_data['year'] == cutoff_year]\n",
    "    future_combos = yearly_data[yearly_data['year'] > cutoff_year]\n",
    "    \n",
    "    # get lists of every lobbyist and politician\n",
    "    politician_lists = master_df_sub[master_df_sub['sponsors'].str.len()>0]['sponsors']\n",
    "    lobbyist_lists = master_df_sub[master_df_sub['lobbyists'].str.len()>0]['lobbyists']\n",
    "    \n",
    "    # get final list of each unique politician and lobbyist\n",
    "    all_politicians = [x for i in politician_lists for x in i]\n",
    "    all_lobbyists = [x for i in lobbyist_lists for x in i]\n",
    "    \n",
    "    # all existing lobbyist, politician pairs\n",
    "    all_existing = [x for i in existing_combos['sponsor_lobbyist_combos'] for x in i]\n",
    "    # all future lobbyist, politician pairs (may include nodes not in \"existing\" graph)\n",
    "    all_future = [x for i in future_combos['sponsor_lobbyist_combos'] for x in i]\n",
    "    \n",
    "    # graph for cutoff_year\n",
    "    yearly_current_graph = nx.Graph()\n",
    "    yearly_current_graph.add_edges_from(all_existing) #add all nodes & edges at once\n",
    "    \n",
    "    #graph for future years\n",
    "    yearly_future_graph = nx.Graph()\n",
    "    yearly_future_graph.add_edges_from(all_future) #add all nodes & edges at once\n",
    "    \n",
    "    # all possible politicians and lobbyists at time graph was made\n",
    "    yearly_current_graph_nodes = list(yearly_current_graph.nodes())\n",
    "\n",
    "    # all possible politicians and lobbyists for future time graph\n",
    "    yearly_future_graph_nodes = list(yearly_future_graph.nodes())\n",
    "    \n",
    "    # non_existent edges at time graph is made\n",
    "    future_targets = list(nx.non_edges(yearly_current_graph))\n",
    "    \n",
    "    print('number of possible edges, before editing: ' + str(len(future_targets)))\n",
    "    \n",
    "    # get rid of non-existent edges which contain two lobbyists or two politicians \n",
    "    for pair in future_targets:\n",
    "        if pair[0] in all_politicians and pair[1] in all_politicians:\n",
    "            try:\n",
    "                future_targets.remove(pair)\n",
    "            except:\n",
    "                continue\n",
    "        if pair[0] in all_lobbyists and pair[1] in all_lobbyists:\n",
    "            try:\n",
    "                future_targets.remove(pair)\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # create a list of node pairs with connection label, 1 for future connection, 0 for no connection\n",
    "    future_classifications = []\n",
    "    \n",
    "    all_existing\n",
    "\n",
    "    future = 0\n",
    "    not_future = 0\n",
    "\n",
    "    print('number of possible edges, after editing: ' + str(len(future_targets)))\n",
    "    \n",
    "    # for lobbyist, politican not connected\n",
    "    for pair in future_targets:\n",
    "        #check if lobbyist and politician, independently are in future graph nodes\n",
    "        if pair[0] in yearly_future_graph_nodes or pair[1] in yearly_future_graph_nodes:\n",
    "            #if yes, check if lobbyist and politician are a pair in future pairs\n",
    "            if pair in all_future:\n",
    "                future +=1\n",
    "                future_classifications.append([pair, 1])\n",
    "            else:\n",
    "                future_classifications.append([pair, 0])\n",
    "                not_future +=1\n",
    "        else:\n",
    "            future_classifications.append([pair, 0])\n",
    "            not_future +=1\n",
    "            continue\n",
    "\n",
    "    print('number of succesful connections: ' + str(future) + '\\n' +  'number of unsuccesful connections: ' + str(not_future))\n",
    "    \n",
    "#     print(future_classifications)\n",
    "    \n",
    "    return total_graph, future_classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of possible edges, before editing: 1224\n",
      "number of possible edges, after editing: 774\n",
      "number of succesful connections: 4\n",
      "number of unsuccesful connections: 770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nnumber of possible edges, before editing: 56601\\nnumber of possible edges, after editing: 36359\\nnumber of succesful connections: 516\\nnumber of unsuccesful connections: 35843\\n'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicitions_2011 = prediction_function(2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_features(all_data_graph, list_of_edges):\n",
    "    pairs = []\n",
    "    connections = []\n",
    "    \n",
    "    # create dataframe with \n",
    "    edges_df = pd.DataFrame(columns= ['pairs', 'connection'])\n",
    "    for pair in list_of_edges:\n",
    "        pairs.append(pair[0])\n",
    "        connections.append(pair[1])\n",
    "    edges_df[\"pairs\"] = pairs\n",
    "    edges_df[\"connection\"] = connections\n",
    "        \n",
    "    # get common neighbors for nodes\n",
    "    common_neighbors = [len(list(nx.common_neighbors(all_data_graph, edge[0], edge[1]))) for edge in edges_df.pairs]\n",
    "    \n",
    "    # get resource allocation index\n",
    "    resource_allocation_index = [item[2] for item in list(nx.resource_allocation_index(all_data_graph, ebunch = edges_df.pairs))]\n",
    "    \n",
    "    # get jaccard coefficent \n",
    "    jaccard_coefficient = [item[2] for item in list(nx.jaccard_coefficient(all_data_graph, ebunch=edges_df.pairs))]\n",
    "   \n",
    "    # get shortest paths\n",
    "    shortest_paths = []\n",
    "    for edge in edges_df.pairs:\n",
    "        path = nx.shortest_path_length(all_data_graph, edge[0], edge[1])\n",
    "        shortest_paths.append(path)\n",
    "    \n",
    "    # get preferential treatment\n",
    "    preferential_attachment = [item[2] for item in list(nx.preferential_attachment(all_data_graph, ebunch = edges_df.pairs))]\n",
    "     \n",
    "    edges_df['Common Neighbors'] = common_neighbors\n",
    "    edges_df['Jaccard Coefficient'] = jaccard_coefficient\n",
    "    edges_df['Resource Allocation Index'] = resource_allocation_index\n",
    "    edges_df['Preferential Attachment'] = preferential_attachment\n",
    "    edges_df['Shortest Paths'] = shortest_paths\n",
    "    \n",
    "    edges_df.set_index('pairs', inplace = True)\n",
    "    \n",
    "    return edges_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>connection</th>\n",
       "      <th>Common Neighbors</th>\n",
       "      <th>Jaccard Coefficient</th>\n",
       "      <th>Resource Allocation Index</th>\n",
       "      <th>Preferential Attachment</th>\n",
       "      <th>Shortest Paths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairs</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(Sampson, John, Gelman, Matt)</th>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>4.872675</td>\n",
       "      <td>4320</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Sampson, John, Moran, James)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Sampson, John, Humphries, Fred)</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>2.758294</td>\n",
       "      <td>2640</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Sampson, John, Grab, Francis)</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Sampson, John, Garrett-Nelson, Labrenda)</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.168870</td>\n",
       "      <td>420</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Reid, Harry, Giordano, Nick)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>675</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Reid, Harry, Grab, Francis)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Giordano, Nick, Smith, Lamar)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Howell, Andrew, Smith, Lamar)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>837</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Smith, Lamar, Grab, Francis)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>774 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           connection  Common Neighbors  \\\n",
       "pairs                                                                     \n",
       "(Sampson, John, Gelman, Matt)                       0                60   \n",
       "(Sampson, John, Moran, James)                       0                 0   \n",
       "(Sampson, John, Humphries, Fred)                    0                38   \n",
       "(Sampson, John, Grab, Francis)                      0                 1   \n",
       "(Sampson, John, Garrett-Nelson, Labrenda)           0                 3   \n",
       "...                                               ...               ...   \n",
       "(Reid, Harry, Giordano, Nick)                       0                 0   \n",
       "(Reid, Harry, Grab, Francis)                        0                 0   \n",
       "(Giordano, Nick, Smith, Lamar)                      0                 0   \n",
       "(Howell, Andrew, Smith, Lamar)                      0                 0   \n",
       "(Smith, Lamar, Grab, Francis)                       0                 0   \n",
       "\n",
       "                                           Jaccard Coefficient  \\\n",
       "pairs                                                            \n",
       "(Sampson, John, Gelman, Matt)                         0.833333   \n",
       "(Sampson, John, Moran, James)                         0.000000   \n",
       "(Sampson, John, Humphries, Fred)                      0.575758   \n",
       "(Sampson, John, Grab, Francis)                        0.016393   \n",
       "(Sampson, John, Garrett-Nelson, Labrenda)             0.046875   \n",
       "...                                                        ...   \n",
       "(Reid, Harry, Giordano, Nick)                         0.000000   \n",
       "(Reid, Harry, Grab, Francis)                          0.000000   \n",
       "(Giordano, Nick, Smith, Lamar)                        0.000000   \n",
       "(Howell, Andrew, Smith, Lamar)                        0.000000   \n",
       "(Smith, Lamar, Grab, Francis)                         0.000000   \n",
       "\n",
       "                                           Resource Allocation Index  \\\n",
       "pairs                                                                  \n",
       "(Sampson, John, Gelman, Matt)                               4.872675   \n",
       "(Sampson, John, Moran, James)                               0.000000   \n",
       "(Sampson, John, Humphries, Fred)                            2.758294   \n",
       "(Sampson, John, Grab, Francis)                              0.034483   \n",
       "(Sampson, John, Garrett-Nelson, Labrenda)                   0.168870   \n",
       "...                                                              ...   \n",
       "(Reid, Harry, Giordano, Nick)                               0.000000   \n",
       "(Reid, Harry, Grab, Francis)                                0.000000   \n",
       "(Giordano, Nick, Smith, Lamar)                              0.000000   \n",
       "(Howell, Andrew, Smith, Lamar)                              0.000000   \n",
       "(Smith, Lamar, Grab, Francis)                               0.000000   \n",
       "\n",
       "                                           Preferential Attachment  \\\n",
       "pairs                                                                \n",
       "(Sampson, John, Gelman, Matt)                                 4320   \n",
       "(Sampson, John, Moran, James)                                  180   \n",
       "(Sampson, John, Humphries, Fred)                              2640   \n",
       "(Sampson, John, Grab, Francis)                                 120   \n",
       "(Sampson, John, Garrett-Nelson, Labrenda)                      420   \n",
       "...                                                            ...   \n",
       "(Reid, Harry, Giordano, Nick)                                  675   \n",
       "(Reid, Harry, Grab, Francis)                                    90   \n",
       "(Giordano, Nick, Smith, Lamar)                                 465   \n",
       "(Howell, Andrew, Smith, Lamar)                                 837   \n",
       "(Smith, Lamar, Grab, Francis)                                   62   \n",
       "\n",
       "                                           Shortest Paths  \n",
       "pairs                                                      \n",
       "(Sampson, John, Gelman, Matt)                           2  \n",
       "(Sampson, John, Moran, James)                           3  \n",
       "(Sampson, John, Humphries, Fred)                        2  \n",
       "(Sampson, John, Grab, Francis)                          2  \n",
       "(Sampson, John, Garrett-Nelson, Labrenda)               2  \n",
       "...                                                   ...  \n",
       "(Reid, Harry, Giordano, Nick)                           3  \n",
       "(Reid, Harry, Grab, Francis)                            3  \n",
       "(Giordano, Nick, Smith, Lamar)                          1  \n",
       "(Howell, Andrew, Smith, Lamar)                          3  \n",
       "(Smith, Lamar, Grab, Francis)                           3  \n",
       "\n",
       "[774 rows x 6 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_graph_features(predicitions_2011[0], predicitions_2011[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_2010 = prediction_function(2010)\n",
    "# get_graph_features(predictions_2010[0], predictions_2010[1])\n",
    "# \"\"\"\n",
    "# number of possible edges, before editing: 54532\n",
    "# number of possible edges, after editing: 35528\n",
    "# number of succesful connections: 375\n",
    "# number of unsuccesful connections: 35153\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of possible edges, before editing: 1224\n",
      "number of possible edges, after editing: 774\n",
      "number of succesful connections: 4\n",
      "number of unsuccesful connections: 770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nnumber of possible edges, before editing: 56601\\nnumber of possible edges, after editing: 36359\\nnumber of succesful connections: 516\\nnumber of unsuccesful connections: 35843\\n'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_2011 = prediction_function(2011)\n",
    "model_df = get_graph_features(predictions_2011[0], predictions_2011[1])\n",
    "\"\"\"\n",
    "number of possible edges, before editing: 56601\n",
    "number of possible edges, after editing: 36359\n",
    "number of succesful connections: 516\n",
    "number of unsuccesful connections: 35843\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_2012 = prediction_function(2012)\n",
    "# get_graph_features(predictions_2012[0], predictions_2012[1])\n",
    "# \"\"\"\n",
    "# number of possible edges, before editing: 74121\n",
    "# number of possible edges, after editing: 47483\n",
    "# number of succesful connections: 496\n",
    "# number of unsuccesful connections: 46987\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_2013 = prediction_function(2013)\n",
    "# get_graph_features(predictions_2013[0], predictions_2013[1])\n",
    "# \"\"\"\n",
    "# number of possible edges, before editing: 55865\n",
    "# number of possible edges, after editing: 35734\n",
    "# number of succesful connections: 433\n",
    "# number of unsuccesful connections: 35301\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>connection</th>\n",
       "      <th>Common Neighbors</th>\n",
       "      <th>Jaccard Coefficient</th>\n",
       "      <th>Resource Allocation Index</th>\n",
       "      <th>Preferential Attachment</th>\n",
       "      <th>Shortest Paths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairs</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(Sampson, John, Gelman, Matt)</th>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>4.872675</td>\n",
       "      <td>4320</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Sampson, John, Moran, James)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Sampson, John, Humphries, Fred)</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>2.758294</td>\n",
       "      <td>2640</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Sampson, John, Grab, Francis)</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Sampson, John, Garrett-Nelson, Labrenda)</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.168870</td>\n",
       "      <td>420</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           connection  Common Neighbors  \\\n",
       "pairs                                                                     \n",
       "(Sampson, John, Gelman, Matt)                       0                60   \n",
       "(Sampson, John, Moran, James)                       0                 0   \n",
       "(Sampson, John, Humphries, Fred)                    0                38   \n",
       "(Sampson, John, Grab, Francis)                      0                 1   \n",
       "(Sampson, John, Garrett-Nelson, Labrenda)           0                 3   \n",
       "\n",
       "                                           Jaccard Coefficient  \\\n",
       "pairs                                                            \n",
       "(Sampson, John, Gelman, Matt)                         0.833333   \n",
       "(Sampson, John, Moran, James)                         0.000000   \n",
       "(Sampson, John, Humphries, Fred)                      0.575758   \n",
       "(Sampson, John, Grab, Francis)                        0.016393   \n",
       "(Sampson, John, Garrett-Nelson, Labrenda)             0.046875   \n",
       "\n",
       "                                           Resource Allocation Index  \\\n",
       "pairs                                                                  \n",
       "(Sampson, John, Gelman, Matt)                               4.872675   \n",
       "(Sampson, John, Moran, James)                               0.000000   \n",
       "(Sampson, John, Humphries, Fred)                            2.758294   \n",
       "(Sampson, John, Grab, Francis)                              0.034483   \n",
       "(Sampson, John, Garrett-Nelson, Labrenda)                   0.168870   \n",
       "\n",
       "                                           Preferential Attachment  \\\n",
       "pairs                                                                \n",
       "(Sampson, John, Gelman, Matt)                                 4320   \n",
       "(Sampson, John, Moran, James)                                  180   \n",
       "(Sampson, John, Humphries, Fred)                              2640   \n",
       "(Sampson, John, Grab, Francis)                                 120   \n",
       "(Sampson, John, Garrett-Nelson, Labrenda)                      420   \n",
       "\n",
       "                                           Shortest Paths  \n",
       "pairs                                                      \n",
       "(Sampson, John, Gelman, Matt)                           2  \n",
       "(Sampson, John, Moran, James)                           3  \n",
       "(Sampson, John, Humphries, Fred)                        2  \n",
       "(Sampson, John, Grab, Francis)                          2  \n",
       "(Sampson, John, Garrett-Nelson, Labrenda)               2  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move index to col\n",
    "model_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "trans_cols = ['Common Neighbors', 'Jaccard Coefficient',\n",
    "       'Resource Allocation Index', 'Preferential Attachment',\n",
    "       'Shortest Paths']\n",
    "\n",
    "other_cols = ['pairs','connection']\n",
    "\n",
    "ct = ColumnTransformer([(\"std\",StandardScaler(),trans_cols)]\n",
    "                       ,remainder='passthrough')\n",
    "\n",
    "model_std = ct.fit_transform(model_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Common Neighbors</th>\n",
       "      <th>Jaccard Coefficient</th>\n",
       "      <th>Resource Allocation Index</th>\n",
       "      <th>Preferential Attachment</th>\n",
       "      <th>Shortest Paths</th>\n",
       "      <th>pairs</th>\n",
       "      <th>connection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.6543</td>\n",
       "      <td>5.66387</td>\n",
       "      <td>11.3785</td>\n",
       "      <td>8.02545</td>\n",
       "      <td>-0.900799</td>\n",
       "      <td>(Sampson, John, Gelman, Matt)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.268846</td>\n",
       "      <td>-0.30331</td>\n",
       "      <td>-0.21843</td>\n",
       "      <td>-0.327374</td>\n",
       "      <td>0.19202</td>\n",
       "      <td>(Sampson, John, Moran, James)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.64918</td>\n",
       "      <td>3.81947</td>\n",
       "      <td>6.34627</td>\n",
       "      <td>4.6359</td>\n",
       "      <td>-0.900799</td>\n",
       "      <td>(Sampson, John, Humphries, Fred)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.0867928</td>\n",
       "      <td>-0.185923</td>\n",
       "      <td>-0.136362</td>\n",
       "      <td>-0.448429</td>\n",
       "      <td>-0.900799</td>\n",
       "      <td>(Sampson, John, Grab, Francis)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.277314</td>\n",
       "      <td>0.0323436</td>\n",
       "      <td>0.183478</td>\n",
       "      <td>0.156848</td>\n",
       "      <td>-0.900799</td>\n",
       "      <td>(Sampson, John, Garrett-Nelson, Labrenda)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>-0.268846</td>\n",
       "      <td>-0.30331</td>\n",
       "      <td>-0.21843</td>\n",
       "      <td>0.671334</td>\n",
       "      <td>0.19202</td>\n",
       "      <td>(Reid, Harry, Giordano, Nick)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>-0.268846</td>\n",
       "      <td>-0.30331</td>\n",
       "      <td>-0.21843</td>\n",
       "      <td>-0.508957</td>\n",
       "      <td>0.19202</td>\n",
       "      <td>(Reid, Harry, Grab, Francis)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>-0.268846</td>\n",
       "      <td>-0.30331</td>\n",
       "      <td>-0.21843</td>\n",
       "      <td>0.24764</td>\n",
       "      <td>-1.99362</td>\n",
       "      <td>(Giordano, Nick, Smith, Lamar)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>-0.268846</td>\n",
       "      <td>-0.30331</td>\n",
       "      <td>-0.21843</td>\n",
       "      <td>0.998183</td>\n",
       "      <td>0.19202</td>\n",
       "      <td>(Howell, Andrew, Smith, Lamar)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>-0.268846</td>\n",
       "      <td>-0.30331</td>\n",
       "      <td>-0.21843</td>\n",
       "      <td>-0.565449</td>\n",
       "      <td>0.19202</td>\n",
       "      <td>(Smith, Lamar, Grab, Francis)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>774 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Common Neighbors Jaccard Coefficient Resource Allocation Index  \\\n",
       "0            10.6543             5.66387                   11.3785   \n",
       "1          -0.268846            -0.30331                  -0.21843   \n",
       "2            6.64918             3.81947                   6.34627   \n",
       "3         -0.0867928           -0.185923                 -0.136362   \n",
       "4           0.277314           0.0323436                  0.183478   \n",
       "..               ...                 ...                       ...   \n",
       "769        -0.268846            -0.30331                  -0.21843   \n",
       "770        -0.268846            -0.30331                  -0.21843   \n",
       "771        -0.268846            -0.30331                  -0.21843   \n",
       "772        -0.268846            -0.30331                  -0.21843   \n",
       "773        -0.268846            -0.30331                  -0.21843   \n",
       "\n",
       "    Preferential Attachment Shortest Paths  \\\n",
       "0                   8.02545      -0.900799   \n",
       "1                 -0.327374        0.19202   \n",
       "2                    4.6359      -0.900799   \n",
       "3                 -0.448429      -0.900799   \n",
       "4                  0.156848      -0.900799   \n",
       "..                      ...            ...   \n",
       "769                0.671334        0.19202   \n",
       "770               -0.508957        0.19202   \n",
       "771                 0.24764       -1.99362   \n",
       "772                0.998183        0.19202   \n",
       "773               -0.565449        0.19202   \n",
       "\n",
       "                                         pairs connection  \n",
       "0                (Sampson, John, Gelman, Matt)          0  \n",
       "1                (Sampson, John, Moran, James)          0  \n",
       "2             (Sampson, John, Humphries, Fred)          0  \n",
       "3               (Sampson, John, Grab, Francis)          0  \n",
       "4    (Sampson, John, Garrett-Nelson, Labrenda)          0  \n",
       "..                                         ...        ...  \n",
       "769              (Reid, Harry, Giordano, Nick)          0  \n",
       "770               (Reid, Harry, Grab, Francis)          0  \n",
       "771             (Giordano, Nick, Smith, Lamar)          0  \n",
       "772             (Howell, Andrew, Smith, Lamar)          0  \n",
       "773              (Smith, Lamar, Grab, Francis)          0  \n",
       "\n",
       "[774 rows x 7 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df_std = pd.DataFrame(data=model_std, columns=trans_cols+other_cols)\n",
    "model_df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move pairs back to index\n",
    "model_df_std.set_index(keys='pairs', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df_std['connection'] = model_df_std['connection'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=model_df_std[['Common Neighbors', 'Jaccard Coefficient', 'Resource Allocation Index',\n",
    "       'Preferential Attachment', 'Shortest Paths']]\n",
    "# X=model_df_std[['Jaccard Coefficient','Preferential Attachment', 'Shortest Paths']] #results are generally better with all 5 features above\n",
    "y=model_df_std['connection']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=5, strategy='stratified')"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy = DummyClassifier(strategy='most_frequent',random_state=5) #achieves 0.99391256, 0.0\n",
    "dummy = DummyClassifier(strategy='stratified',random_state=5) #achieves 0.98619696, 0.00668896\n",
    "# dummy = DummyClassifier(strategy='prior',random_state=5) # achieves 0.99391256, 0.0\n",
    "# dummy = DummyClassifier(strategy='constant',random_state=5, constant='1') #achieves 0.0, 0.02391304\n",
    "\n",
    "dummy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99352052, 0.        ])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# f1_score(y_test, dummy.predict(X_test), average='weighted') #this scoring = 0.982\n",
    "# f1_score(y_test, dummy.predict(X_test), average='binary', pos_label='1') #this scoring = 0.0\n",
    "f1_score(y_test, dummy.predict(X_test), average=None) #this scoring = 0.0 for 1/positive class, 0.994 for 0/negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[230,   1],\n",
       "       [  2,   0]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.unique(dummy.predict(X_test),return_counts=True)\n",
    "\n",
    "confusion_matrix(y_test, dummy.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### A baseline Dummy Classifier model achieves an f1 score of <span style=\"color:magenta\"> 0.01 </span> for the positive label (a connection being formed) for which it predicts <span style=\"color:magenta\"> 140 </span> such instances in the test data and <span style=\"color:magenta\"> 0.986 </span> for the negative label (no connection being formed) for which it predicts <span style=\"color:magenta\"> 10,864 </span> such instances in the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=5, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "base_lr = LogisticRegression(random_state=5)\n",
    "\n",
    "base_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99568966, 0.        ])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# f1_score(y_test, base_lr.predict(X_test), average='weighted') #this scoring = 0.984\n",
    "# f1_score(y_test, base_lr.predict(X_test), average='binary', pos_label='1') #this scoring = 0.191\n",
    "f1_score(y_test, base_lr.predict(X_test), average=None) #this scoring = 0.191 for 1/positive class, 0.994 for 0/negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[231,   0],\n",
       "       [  2,   0]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.unique(base_lr.predict(X_test),return_counts=True)\n",
    "\n",
    "confusion_matrix(y_test, base_lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### A baseline Logistic Regression model achieves an f1 score of 0.024 for the positive label (a connection being formed) for which it predicts 3 such instances in the test data and 0.992 for the negative label (no connection being formed) for which it predicts 11,001 such instances in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=5, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 1, 10, 100],\n",
       "                         'class_weight': ['balanced', None],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "lr_params = {'C':[.001,.01,1,10,100],\n",
    "            'class_weight':['balanced',None],\n",
    "            'penalty':['l1', 'l2']}\n",
    "lr_clf = GridSearchCV(estimator=base_lr, param_grid=lr_params, cv=5, n_jobs=-1, \n",
    "                      scoring='f1_weighted') #including a scoring metric helped A LOT\n",
    "\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=5, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99568966, 0.        ])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, lr_clf.predict(X_test), average=None) #this scoring = 0.556 for 1/positive class, 0.990 for 0/negative class\n",
    "# f1_score(y_test, lr_clf.predict(X_test), average='weighted') #this scoring = 0.985\n",
    "# f1_score(y_test, base_lr.predict(X_test), average='binary', pos_label='1') #this scoring = 0.191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[231,   0],\n",
       "       [  2,   0]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.unique(lr_clf.predict(X_test),return_counts=True)\n",
    "\n",
    "confusion_matrix(y_test, lr_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### A Logistic Regression model improved by Grid Search achieves an f1 score of <span style=\"color:magenta\"> 0.605 </span> for the positive label (a connection being formed) for which it predicts <span style=\"color:magenta\"> 383 </span> such instances in the test data and <span style=\"color:magenta\"> 0.990 </span> for the negative label (no connection being formed) for which it predicts <span style=\"color:magenta\"> 10,621 </span> such instances in the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_svm = SVC(random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=5, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99568966, 0.        ])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1_score(y_test, base_svm.predict(X_test), average='weighted') #this scoring = 0.983\n",
    "# f1_score(y_test, base_svm.predict(X_test), average='binary', pos_label='1') #this scoring = 0.058\n",
    "f1_score(y_test, base_svm.predict(X_test), average=None) #this scoring = 0.058 for 1/positive class, 0.994 for 0/negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[231,   0],\n",
       "       [  2,   0]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.unique(base_svm.predict(X_test),return_counts=True)\n",
    "\n",
    "confusion_matrix(y_test, base_svm.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### A baseline Support Vector Machine model achieves an f1 score of 0.0 for the positive label (a connection being formed) for which it predicts 0 such instances in the test data and 0.992 for the negative label (no connection being formed) for which it predicts 11,004 such instances in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=5, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [1, 10, 100], 'class_weight': ['balanced', None],\n",
       "                         'decision_function_shape': ['ovo', 'ovr'],\n",
       "                         'gamma': ['scale', 'auto'], 'kernel': ['rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# svm_params = {'C':[.001,.01,1,10,100],\n",
    "#               'kernel':['rbf','linear','sigmoid','poly'],\n",
    "#             'class_weight':['balanced',None],\n",
    "#             'decision_function_shape':['ovo','ovr']} \n",
    "# \"\"\"\n",
    "# best estimator for the above is:\n",
    "# best estimator here is SVC(C=10, cache_size=200, class_weight='balanced', coef0=0.0,\n",
    "#     decision_function_shape='ovo', degree=3, gamma='auto_deprecated',\n",
    "#     kernel='rbf', max_iter=-1, probability=False, random_state=5,\n",
    "#     shrinking=True, tol=0.001, verbose=False)\n",
    "# \"\"\"\n",
    "\n",
    "svm_params = {'C':[1,10,100],\n",
    "              'kernel':['rbf'],\n",
    "            'class_weight':['balanced',None],\n",
    "            'decision_function_shape':['ovo','ovr'],\n",
    "             'gamma':['scale','auto']}\n",
    "svm_clf = GridSearchCV(estimator=base_svm, param_grid=svm_params, cv=5, n_jobs=-1, \n",
    "                      scoring='f1_weighted')\n",
    "\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovo', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=5, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99568966, 0.        ])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1_score(y_test, svm_clf.predict(X_test), average='weighted') #this scoring = 0.985\n",
    "# f1_score(y_test, svm_clf.predict(X_test), average='binary', pos_label='1') #this scoring = 0.551\n",
    "f1_score(y_test, svm_clf.predict(X_test), average=None) #this scoring = 0.551 for 1/positive class, 0.990 for 0/negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[231,   0],\n",
       "       [  2,   0]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.unique(svm_clf.predict(X_test),return_counts=True)\n",
    "\n",
    "confusion_matrix(y_test, svm_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### A Support Vector Machine model improved by Grid Search achieves an f1 score of <span style=\"color:magenta\"> 0.605 </span> for the positive label (a connection being formed) for which it predicts <span style=\"color:magenta\"> 383 </span> such instances in the test data and <span style=\"color:magenta\"> 0.990 </span> for the negative label (no connection being formed) for which it predicts <span style=\"color:magenta\"> 10,621 </span> such instances in the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dt = DecisionTreeClassifier(random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=5, splitter='best')"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99568966, 0.        ])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1_score(y_test, base_dt.predict(X_test), average='weighted') #this scoring = 0.985\n",
    "# f1_score(y_test, base_dt.predict(X_test), average='binary', pos_label='1') #this scoring = 0.367\n",
    "f1_score(y_test, base_dt.predict(X_test), average=None) #this scoring = 0.367 for 1/positive class, 0.993 for 0/negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[231,   0],\n",
       "       [  2,   0]])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.unique(base_dt.predict(X_test),return_counts=True)\n",
    "\n",
    "confusion_matrix(y_test, base_dt.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### A baseline Decision Tree model achieves an f1 score of 0.508 for the positive label (a connection being formed) for which it predicts 133 such instances in the test data and 0.993 for the negative label (no connection being formed) for which it predicts 10,871 such instances in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=5, splitter='best'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'class_weight': ['balanced', None],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 3, 5, None],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2', None],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_params = {'criterion':['gini','entropy'],\n",
    "             'max_depth':[2,3,5,None],\n",
    "             'splitter':['best','random'],\n",
    "            'class_weight':['balanced',None],\n",
    "            'max_features':['auto','sqrt','log2',None]}\n",
    "dt_clf = GridSearchCV(estimator=base_dt, param_grid=dt_params, cv=5, n_jobs=-1, \n",
    "                      scoring='f1_weighted')\n",
    "\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=5, splitter='best')"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99568966, 0.        ])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1_score(y_test, dt_clf.predict(X_test), average='weighted') #this scoring = 0.985\n",
    "# f1_score(y_test, dt_clf.predict(X_test), average='binary', pos_label='1') #this scoring = 0.448\n",
    "f1_score(y_test, dt_clf.predict(X_test), average=None) #this scoring = 0.448 for 1/positive class, 0.992 for 0/negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[231,   0],\n",
       "       [  2,   0]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.unique(dt_clf.predict(X_test),return_counts=True)\n",
    "\n",
    "confusion_matrix(y_test, dt_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### A Decision Tree model improved by Grid Search achieves an f1 score of <span style=\"color:magenta\"> 0.508 </span> for the positive label (a connection being formed) for which it predicts <span style=\"color:magenta\"> 133 </span> such instances in the test data and <span style=\"color:magenta\"> 0.993 </span> for the negative label (no connection being formed) for which it predicts <span style=\"color:magenta\"> 10,871 </span> such instances in the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=5, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_rf = RandomForestClassifier(random_state=5)\n",
    "\n",
    "base_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99568966, 0.        ])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1_score(y_test, base_rf.predict(X_test), average='weighted')\n",
    "# f1_score(y_test, base_rf.predict(X_test), average='binary', pos_label='1') \n",
    "f1_score(y_test, base_rf.predict(X_test), average=None) #this scoring = 0.495 for 1/positive class, 0.993 for 0/negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[231,   0],\n",
       "       [  2,   0]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, base_rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=5,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'class_weight': ['balanced', None],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 3, 5, None],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2', None]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = {'criterion':['gini','entropy'],\n",
    "             'max_depth':[2,3,5,None],\n",
    "            'class_weight':['balanced',None],\n",
    "            'max_features':['auto','sqrt','log2',None]}\n",
    "rf_clf = GridSearchCV(estimator=base_rf, param_grid=rf_params, cv=5, n_jobs=-1, \n",
    "                      scoring='f1_weighted')\n",
    "\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99568966, 0.        ])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1_score(y_test, rf_clf.predict(X_test), average='weighted')\n",
    "# f1_score(y_test, rf_clf.predict(X_test), average='binary', pos_label='1')\n",
    "f1_score(y_test, rf_clf.predict(X_test), average=None) #this scoring = 0.495 for 1/positive class, 0.993 for 0/negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[231,   0],\n",
       "       [  2,   0]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, rf_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best RF & get feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestClassifier(class_weight=None,criterion='entropy',max_depth= None,max_features='auto',random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99568966, 0.        ])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf.fit(X_train, y_train)\n",
    "f1_score(y_test, best_rf.predict(X_test), average=None) #this scoring = 0.495 for 1/positive class, 0.993 for 0/negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[231,   0],\n",
       "       [  2,   0]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, best_rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00477019, 0.01076559, 0.00925277, 0.66936835, 0.30584311])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Preferential Attachment', 0.6693683480176223),\n",
       " ('Shortest Paths', 0.3058431109018061),\n",
       " ('Jaccard Coefficient', 0.010765585109202391),\n",
       " ('Resource Allocation Index', 0.009252769459628229),\n",
       " ('Common Neighbors', 0.004770186511740942)]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(zip(X_train.columns, best_rf.feature_importances_))\n",
    "sorted(zip(X_train.columns, best_rf.feature_importances_),key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### <span style=\"color:magenta\"> Feature importances ^ </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model scores & counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "[0.99568966 0.        ]\n",
      "[[231   0]\n",
      " [  2   0]]\n",
      "\n",
      "SVM\n",
      "[0.99568966 0.        ]\n",
      "[[231   0]\n",
      " [  2   0]]\n",
      "\n",
      "Dummy\n",
      "[0.99352052 0.        ]\n",
      "[[230   1]\n",
      " [  2   0]]\n",
      "\n",
      "Logistic Regression\n",
      "[0.99568966 0.        ]\n",
      "[[231   0]\n",
      " [  2   0]]\n",
      "\n",
      "Random Forest\n",
      "[0.99568966 0.        ]\n",
      "[[231   0]\n",
      " [  2   0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get all model scores\n",
    "models = {'Decision Tree':dt_clf,\n",
    "          'SVM':svm_clf,\n",
    "         'Dummy':dummy,\n",
    "         'Logistic Regression':lr_clf,\n",
    "         'Random Forest':rf_clf}\n",
    "\n",
    "for k,v in models.items():\n",
    "    score = f1_score(y_test, v.predict(X_test), average=None)\n",
    "    matrix = confusion_matrix(y_test, v.predict(X_test))\n",
    "    print(f\"{k}\\n{score}\\n{matrix}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
